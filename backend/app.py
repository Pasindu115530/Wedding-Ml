from flask import Flask, request, jsonify
import pandas as pd
import joblib
import os

app = Flask(__name__)

# --- Load ML Artifacts ---
# These must be generated by running your train_model.py script first
try:
    model = joblib.load("wedding_cost_model.pkl")
    scaler = joblib.load("scaler.pkl")
    label_encoders = joblib.load("label_encoders.pkl")
    medians = joblib.load("medians.pkl") # Dynamic defaults from your Excel data
except FileNotFoundError as e:
    print(f"Error: Missing model files. Run train_model.py first. {e}")
    exit()

# --- Define Feature Structure ---
categorical_features = [
    'Wedding_Season', 'Venue_Type', 'Catering_Type',
    'Decoration_Level', 'Photography_Package', 'Entertainment_Type'
]
numeric_features = [
    'Guest_Count', 'Venue_Cost_LKR', 'Catering_Cost_LKR',
    'Decoration_Cost_LKR', 'Photography_Cost_LKR', 'Entertainment_Cost_LKR'
]
model_features = categorical_features + numeric_features

@app.route("/predict", methods=["POST"])
def predict():
    data = request.json
    if not data:
        return jsonify({"error": "No input data provided"}), 400

    # 1. Handle Missing Inputs with Medians
    # If the user doesn't provide a cost, the API uses the median from your data.
    input_dict = {}
    for feat in model_features:
        if feat in data:
            input_dict[feat] = data[feat]
        elif feat in medians:
            input_dict[feat] = medians[feat]
        else:
            # Fallback for Guest_Count if not in data or medians
            input_dict[feat] = data.get("Guest_Count", 100) 

    # 2. Pre-process and Re-order Data
    user_df = pd.DataFrame([input_dict])
    user_df = user_df[model_features] # Vital: Ensures column order matches training

    # 3. Label Encoding for Categorical Inputs
    for col, le in label_encoders.items():
        val = str(user_df[col][0]).lower().strip()
        try:
            user_df[col] = le.transform([val])
        except ValueError:
            return jsonify({"error": f"Unknown category '{val}' for {col}. Check your spelling."}), 400

    # 4. Feature Scaling
    user_df[numeric_features] = scaler.transform(user_df[numeric_features])

    # 5. Model Prediction
    predicted_base_cost = float(model.predict(user_df)[0])
    
    # 6. Budget Allocation & Buffer Calculation
    # Adding a 10% contingency buffer to the base prediction
    total_recommended_budget = predicted_base_cost * 1.10
    
    # Standard wedding percentage breakdown
    budget_division = {
        "Venue_and_Catering": round(total_recommended_budget * 0.48, 2), # 48%
        "Photography_and_Video": round(total_recommended_budget * 0.12, 2), # 12%
        "Flowers_and_Decor": round(total_recommended_budget * 0.10, 2),     # 10%
        "Music_and_Entertainment": round(total_recommended_budget * 0.08, 2),# 8%
        "Attire_and_Beauty": round(total_recommended_budget * 0.09, 2),      # 9%
        "Miscellaneous_and_Buffer": round(total_recommended_budget * 0.13, 2) # Remaining
    }

    # 7. Response Format
    return jsonify({
        "status": "success",
        "input_summary": {
            "Guest_Count": input_dict["Guest_Count"],
            "Venue": input_dict["Venue_Type"],
            "Season": input_dict["Wedding_Season"]
        },
        "predicted_base_cost": round(predicted_base_cost, 2),
        "total_recommended_budget": round(total_recommended_budget, 2),
        "suggested_division_LKR": budget_division,
        "message": "The total recommended budget includes a 10% contingency for unexpected fees."
    })

if __name__ == "__main__":
    # Use port 5000 as default or set via environment variable
    app.run(debug=True, port=int(os.environ.get("PORT", 5000)))